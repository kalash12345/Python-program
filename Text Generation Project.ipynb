{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Welcome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing Dependencies\n",
    "import numpy as np\n",
    "import sys\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,LSTM,Flatten\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"frankenstein.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(input):\n",
    "    # lowercase everything to standardize it\n",
    "    input = input.lower()\n",
    "\n",
    "    # instantiate the tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "\n",
    "    # if the created token isn't in the stop words, make it part of \"filtered\"\n",
    "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    return \" \".join(filtered)\n",
    "\n",
    "# preprocess the input data, make tokens\n",
    "processed_inputs = tokenize_words(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chars to numbers\n",
    "chars = sorted(list(set(processed_inputs)))\n",
    "char_to_num = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 269566\n",
      "Total vocab: 38\n"
     ]
    }
   ],
   "source": [
    "# Check if words to chars or chars to num (?!) has worked ?\n",
    "input_len = len(processed_inputs)\n",
    "vocab_len = len(chars)\n",
    "print (\"Total number of characters:\", input_len)\n",
    "print (\"Total vocab:\", vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq length\n",
    "seq_length = 100\n",
    "x_data = []\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 269466\n"
     ]
    }
   ],
   "source": [
    "# Loop through Sequence\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "    in_seq = processed_inputs[i:i + seq_length]\n",
    "    out_seq = processed_inputs[i + seq_length]\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append(char_to_num[out_seq])\n",
    "    \n",
    "n_patterns = len(x_data)\n",
    "print (\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input sequence to np array and so on\n",
    "X = np.reshape(x_data, (n_patterns, seq_length, 1))\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer= 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Weights\n",
    "filepath = \"model_weights_saved.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "269312/269466 [============================>.] - ETA: 12s - loss: 2.8725\n",
      "Epoch 00001: loss improved from inf to 2.87244, saving model to model_weights_saved.hdf5\n",
      "269466/269466 [==============================] - 21716s 81ms/sample - loss: 2.8724\n",
      "Epoch 2/4\n",
      "269312/269466 [============================>.] - ETA: 12s - loss: 2.5781\n",
      "Epoch 00002: loss improved from 2.87244 to 2.57808, saving model to model_weights_saved.hdf5\n",
      "269466/269466 [==============================] - 22410s 83ms/sample - loss: 2.5781\n",
      "Epoch 3/4\n",
      "269312/269466 [============================>.] - ETA: 13s - loss: 2.4113\n",
      "Epoch 00003: loss improved from 2.57808 to 2.41125, saving model to model_weights_saved.hdf5\n",
      "269466/269466 [==============================] - 23379s 87ms/sample - loss: 2.4113\n",
      "Epoch 4/4\n",
      "269312/269466 [============================>.] - ETA: 12s - loss: 2.2921\n",
      "Epoch 00004: loss improved from 2.41125 to 2.29203, saving model to model_weights_saved.hdf5\n",
      "269466/269466 [==============================] - 21883s 81ms/sample - loss: 2.2920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a30596bf08>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model and train it\n",
    "model.fit(X, y, epochs=4, batch_size=256, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile model with the saved weights\n",
    "filename = 'model_weights_saved.hdf5'\n",
    "model.load_weights(filename)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of the model back into characters\n",
    "num_to_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed : \n",
      "\" death knell appeared like dream yet distinct oppressive reality sun far descended still sat shore sa \"\n"
     ]
    }
   ],
   "source": [
    "# Random seed to help generate\n",
    "start = np.random.randint(0 , len(x_data) - 1)\n",
    "pattern = x_data[start]\n",
    "print('Random Seed : ')\n",
    "print(\"\\\"\",''.join([num_to_char[value] for value in pattern]),\"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsed serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter serter s"
     ]
    }
   ],
   "source": [
    "# Generate the text\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern , (1 , len(pattern) , 1))\n",
    "    x = x / float(vocab_len)\n",
    "    prediction = model.predict(x , verbose = 0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = num_to_char[index]\n",
    "    seq_in = [num_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
